# SyncedMemory

[![CI](https://github.com/zhenfeizhang/synced-memory/workflows/CI/badge.svg)](https://github.com/zhenfeizhang/synced-memory/actions)

A high-performance, lock-free data structure for coordinating memory access between threads in a write-then-read pattern. Perfect for scenarios where multiple threads need to perform coordinated computation cycles with synchronized data sharing.

## üöÄ Features

- **Lock-Free Performance**: Uses atomic operations and barriers instead of mutexes
- **Segmented Memory**: Each thread has exclusive access to its own memory segment
- **Automatic Synchronization**: Built-in barriers coordinate write-then-read cycles
- **Memory Safety**: Prevents data races through careful design and `UnsafeCell`
- **Zero-Copy Reads**: Direct memory access for maximum performance
- **Flexible Data Types**: Generic over any `Default + Clone + Copy` type

## üèóÔ∏è Architecture

```
Thread 0: [data...] | Thread 1: [data...] | Thread 2: [data...] | Thread N: [data...]
          ^                      ^                      ^                      ^
          |                      |                      |                      |
 LocalMemHandler(0)     LocalMemHandler(1)     LocalMemHandler(2)     LocalMemHandler(N)
```

### How It Works

1. **Segmented Memory**: Total memory is divided into `num_threads √ó segment_size` elements
2. **Exclusive Writes**: Each thread writes only to its own segment (no contention)
3. **Atomic Coordination**: Timestamps and barriers coordinate global synchronization
4. **Synchronized Reads**: All threads can read the complete global state once synchronized

## üì¶ Installation

Add this to your `Cargo.toml`:

```toml
[dependencies]
synced-memory = { git = "https://github.com/zhenfeizhang/synced-memory" }
```

## üîß Quick Start

```rust
use std::sync::Arc;
use std::thread;
use synced_memory::SynchedMemory;

fn main() {
    // Create synchronized memory for 4 threads, 10 elements per thread
    let memory = Arc::new(SynchedMemory::<i32>::new(4, 10));

    let handles: Vec<_> = (0..4).map(|thread_id| {
        let mem = Arc::clone(&memory);
        thread::spawn(move || {
            // Each thread gets its own local memory handler
            let local_handler = mem.build_local_handler(thread_id);
            
            // Write data and automatically sync with other threads
            let data = vec![thread_id as i32; 5];
            let global_data = mem.write_local_memory_and_sync_read(&local_handler, &data);
            
            // All threads have now written and read the synchronized state
            println!("Thread {} sees {} total elements", thread_id, global_data.len());
            
            // Verify our data is in the global state
            let start_idx = thread_id * 10;
            assert_eq!(&global_data[start_idx..start_idx + 5], &data);
        })
    }).collect();

    for handle in handles {
        handle.join().unwrap();
    }
}
```

## üí° Use Cases

### Parallel Simulation
Perfect for iterative simulations where threads compute local state and then need to observe the global state:

```rust
// Game of Life, physics simulations, cellular automata, etc.
let grid = Arc::new(SynchedMemory::<Cell>::new(num_workers, cells_per_worker));

for iteration in 0..1000 {
    // Each worker computes its portion
    let global_state = grid.write_local_memory_and_sync_read(&local_handler, &new_cells);
    
    // Workers can now see neighbors' updates for next iteration
    plan_next_iteration(&global_state);
}
```

### Distributed Computing
Coordinate work across multiple threads with synchronized checkpoints:

```rust
// Map-reduce style operations, distributed algorithms
let shared_state = Arc::new(SynchedMemory::<WorkResult>::new(workers, results_per_worker));

loop {
    let local_results = compute_work_chunk();
    let global_results = shared_state.write_local_memory_and_sync_read(&handler, &local_results);
    
    if convergence_check(&global_results) {
        break;
    }
}
```

### Real-Time Systems
High-performance coordination for real-time applications:

```rust
// Audio processing, game engines, control systems
let audio_buffers = Arc::new(SynchedMemory::<f32>::new(channels, samples_per_channel));

// Each channel processes audio independently, then sync for mixing
let processed_audio = audio_buffers.write_local_memory_and_sync_read(&channel_handler, &samples);
mix_channels(&processed_audio);
```

## üîÑ Write-Then-Read Pattern

The core pattern is simple and powerful:

```rust
// 1. Each thread writes to its own segment
memory.write_local_memory(&local_handler, &my_data);

// 2. Automatic synchronization (built into the API)
//    - All threads wait until everyone finishes writing
//    - Global state becomes available

// 3. All threads read the complete synchronized state
let global_data = memory.write_local_memory_and_sync_read(&local_handler, &my_data);

// 4. Threads can now process the global state
process_global_state(&global_data);
```

## üöÄ Performance

### Benchmarks (16 threads, 1000 iterations)

| Operation | Time | Throughput |
|-----------|------|------------|
| Write + Sync + Read | ~2.3ms | ~430K ops/sec |
| Memory Allocation | One-time | Amortized |
| Lock Contention | None | Lock-free |

### Performance Characteristics

- **O(1) Write Complexity**: Each thread writes to its own segment
- **O(n) Read Complexity**: Must copy entire global state (configurable)
- **Memory Usage**: `num_threads √ó segment_size √ó sizeof(T)`
- **Cache Efficiency**: Each thread works on its own cache lines

## üõ°Ô∏è Safety Guarantees

### Memory Safety
- **No Data Races**: Each thread has exclusive write access to its segment
- **Atomic Coordination**: All synchronization uses atomic operations
- **Validated Access**: Bounds checking prevents buffer overflows
- **Type Safety**: Generic design ensures type consistency

### Thread Safety
- **Segmented Access**: Threads never write to the same memory locations  
- **Barrier Synchronization**: Coordinated write-then-read phases
- **Timestamp Validation**: Prevents out-of-order operations
- **Safe Interior Mutability**: `UnsafeCell` used correctly with external coordination

## üìä API Reference

### Core Types

```rust
// Main synchronized memory structure
SynchedMemory<T: Default + Clone + Copy>

// Handle for thread-local memory access
LocalMemHandler<T>
```

### Key Methods

```rust
// Create new synchronized memory
SynchedMemory::new(num_threads: usize, segment_size: usize) -> Self

// Get thread's local memory handle  
build_local_handler(thread_id: usize) -> LocalMemHandler<T>

// Write data and sync with all threads (recommended)
write_local_memory_and_sync_read(&local_handler, data: &[T]) -> Vec<T>

// Low-level operations
write_local_memory(&local_handler, data: &[T])  // Write only
read_global() -> Vec<T>                        // Direct read
wait_write_barrier()                          // Manual barrier
update_global_timestamp()                    // Advance global state
```

## üîß Advanced Usage

### Multiple Iterations

```rust
let memory = Arc::new(SynchedMemory::<f64>::new(threads, segment_size));

for iteration in 0..num_iterations {
    // Each thread computes based on previous global state
    let new_data = compute_iteration(iteration, &previous_global_state);
    
    // Sync and get new global state
    let global_state = memory.write_local_memory_and_sync_read(&local_handler, &new_data);
    
    // Advance to next iteration (typically done by one thread)
    if thread_id == 0 {
        memory.update_global_timestamp();
    }
    
    previous_global_state = global_state;
}
```

### Custom Synchronization

```rust
// For advanced users who need manual control
memory.write_local_memory(&local_handler, &data);
memory.wait_write_barrier();  // Wait for all writes
let global_data = memory.read_global();  // Get synchronized state
```

### Error Handling

```rust
// The API uses panics for programming errors (like bounds violations)
// Wrap in catch_unwind for graceful error handling if needed
let result = std::panic::catch_unwind(|| {
    memory.write_local_memory_and_sync_read(&local_handler, &data)
});

match result {
    Ok(global_data) => process_data(global_data),
    Err(_) => handle_panic_error(),
}
```

## üß™ Testing

Run the comprehensive test suite:

```bash
# Basic tests
cargo test

# With output
cargo test -- --nocapture

# Performance test with 16 threads, 10 iterations
cargo test test_end_to_end_write_read_cycle -- --nocapture
```

The test suite includes:
- Basic functionality tests
- Edge case validation  
- Multi-threaded stress tests
- Performance benchmarks
- Memory safety verification

## üìà Performance Tips

### Memory Layout
- **Size segments appropriately**: Larger segments reduce coordination overhead
- **Consider cache lines**: Align segment sizes to cache boundaries when possible
- **Memory allocation**: Pre-allocate all memory upfront (zero allocation during operation)

### Thread Coordination
- **Minimize global timestamp updates**: Only update when necessary
- **Balance work**: Ensure threads finish writing at roughly the same time
- **Consider NUMA**: Pin threads to cores for consistent performance

### Data Types
- **Prefer Copy types**: Avoid expensive Clone operations
- **Consider alignment**: Well-aligned types perform better
- **Size matters**: Smaller types reduce memory bandwidth requirements

## ü§ù Contributing

Contributions welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
git clone https://github.com/zhenfeizhang/synced-memory
cd synced-memory
cargo build
cargo test
```

## üôè Acknowledgments

- Inspired by high-performance computing patterns
- Built with Rust's safety and performance guarantees
- Designed for real-world multi-threaded applications

---

**Questions?** Open an issue at https://github.com/zhenfeizhang/synced-memory/issues

**Performance critical?** We'd love to hear about your use case!